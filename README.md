# LipSync

This project has been built on google colab. To use this model follow the steps mentioned below:
1. open the .pynb file on colab
2. select custom path as upload method. Add the path to your video file in the placeholder.
3. Select custom path as upload method. Add the path to the audio file.
4. run all the cells in the same order.
5. download the lipsynced video from the result foler in Wav2Lip.

   This model was cloned from this link https://github.com/Rudrabha/Wav2Lip.
   Wav2lip is a model that requires a face to be present in every frame in order to lip sync accurately.

   Result folder link :- https://drive.google.com/drive/folders/1bI82znvNMKSmMlqIcX_p19V0WQUUDjN9?usp=sharing
